# Twitter Sentiment Analysis â€” TF-IDF + Logistic Regression & BERT

## ğŸ“Œ Objective
The main objective of this project is to classify tweets into three sentiment categories â€” Positive, Negative, and Neutral â€” using both traditional Machine Learning (TF-IDF + Logistic Regression) and a deep learning approach (BERT).
The project demonstrates the end-to-end process from data cleaning, EDA (Exploratory Data Analysis), model training, evaluation, and model saving.

## ğŸ¯ Aims
- Perform sentiment classification on tweets mentioning various entities.
- Compare the performance of a traditional ML model (TF-IDF + Logistic Regression) and a transformer-based model (BERT).
- Preprocess and clean text to remove noise such as URLs, mentions, and special characters.
- Visualize sentiment distribution and frequent words per sentiment.
- Save trained models for future deployment.

## ğŸ“‚ Dataset Used
Source: https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis

**Files/**
- `twitter_training.csv` â€” Training data **(55,328 rows Ã— 4 columns)**
- `twitter_validation.csv` â€” Validation data **(3,799 rows Ã— 4 columns)**
  
## ğŸ›  Tech Stack
### Languages: Python
### Libraries & Frameworks:
- Data Handling & Analysis: pandas, numpy
- Visualization: matplotlib, seaborn, WordCloud
- Machine Learning: scikit-learn (TfidfVectorizer, LogisticRegression)
- Deep Learning: TensorFlow, Transformers (BERT)
- Utilities: joblib, zipfile, shutil
### Models:
- TF-IDF + Logistic Regression (Baseline)
- BERT (bert-base-uncased) for sequence classification

## ğŸ“‹ Project Overview & Process
- 1ï¸âƒ£ Data Loading & Preparation
- 2ï¸âƒ£ Data Cleaning
- 3ï¸âƒ£ Exploratory Data Analysis (EDA)
- 4ï¸âƒ£ Model 1: TF-IDF + Logistic Regression
- 5ï¸âƒ£ Model 2: BERT
- 6ï¸âƒ£ Model Comparison
- 7ï¸âƒ£ Random Predictions
- 8ï¸âƒ£ Model Saving
